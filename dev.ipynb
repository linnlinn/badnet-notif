{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tournament.py\n",
    "#========================\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#from badnet.sql_connection import badminton_db\n",
    "#from badnet.utils import logger\n",
    "\n",
    "class Tournament:\n",
    "    def __init__(self, name: str, url: str, date: str, ville: str, departement = \"99\", source=\"badnet\"):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.id = url.split(\"=\")[-1]\n",
    "        self.departement = departement\n",
    "        self.date = date\n",
    "        self.description = ''\n",
    "        self.category = [ 'N', 'R', 'D','P', 'NC']\n",
    "        self.disciplines = ['simple', 'double', 'mixte']\n",
    "        self.age_group = ['jeunes', 'seniors', 'veterans']\n",
    "        self.source = source\n",
    "        self.date_publication = datetime.now()\n",
    "        self.ville = ville\n",
    "        self.date_registration_opening = ''\n",
    "        self.date_registration_closed = ''\n",
    "        self.ja = 'Non renseigné'\n",
    "        self.url_affiche='https://badnet.fr/Img/poster/affiche_default.png'\n",
    "        self.volant = 'Non renseigné'\n",
    "        self.date_publication = datetime.now()\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "\n",
    "        return f\"Tournament {self.id} {self.name}\"\n",
    "\n",
    "    def get_additional_info(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_argument('--window-size=1920x6080')\n",
    "        chromedriver = os.getcwd() + \"/chromedriver\"\n",
    "        self.driver = webdriver.Chrome(options = chrome_options, service=Service(chromedriver))\n",
    "        self.driver.get(self.url)\n",
    "        time.sleep(10)\n",
    "        self.driver.find_element(\"xpath\", \"/html/body/div[2]/div/section/div/div/nav/ul/li[1]/span\").click()\n",
    "        time.sleep(5)\n",
    "        infos = self.driver.find_element(\"class name\", \"infos\")\n",
    "        \n",
    "        dates = self.driver.find_element(\"class name\", \"limit\")\n",
    "\n",
    "        try:\n",
    "            notes = self.driver.find_element(\"class name\", \"text\")\n",
    "            self.description = re.search('Notes des organisateurs\\n((.*\\n*)*)',notes.text).group(1)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Could not extract organizer's notes for {self.name} ID={self.id}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "        ja = re.search('Juge-arbitre : (.+)', infos.text)\n",
    "        self.ja = ja.group(1) if ja else 'unknown'\n",
    "        volant = re.search('Volant officiel : (.+)', infos.text)\n",
    "        self.volant = volant.group(1) if volant else 'unknown'\n",
    "        \n",
    "        try:\n",
    "            simple = infos.text.split('\\n')[infos.text.split('\\n').index('SIMPLE DOUBLE MIXTE')+1].split()[0]=='check'\n",
    "            double = infos.text.split('\\n')[infos.text.split('\\n').index('SIMPLE DOUBLE MIXTE')+1].split()[1]=='check'\n",
    "            mixte = infos.text.split('\\n')[infos.text.split('\\n').index('SIMPLE DOUBLE MIXTE')+1].split()[2]=='check'\n",
    "\n",
    "            discipline = {'simple': simple, 'double': double, 'mixte': mixte}\n",
    "            self.disciplines = [key for key, value in discipline.items() if value]\n",
    "            if self.disciplines==[]:\n",
    "                self.disciplines = ['simple', 'double', 'mixte']\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Could not extract disciplines for {self.name} ID={self.id}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "\n",
    "        try:\n",
    "            jeunes = infos.text.split('\\n')[infos.text.split('\\n').index('JEUNES SÉNIORS VÉTÉRANS HANDIBAD INCLUSIF')+1].split()[0]=='check'\n",
    "            seniors = infos.text.split('\\n')[infos.text.split('\\n').index('JEUNES SÉNIORS VÉTÉRANS HANDIBAD INCLUSIF')+1].split()[1]=='check'\n",
    "            veterans = infos.text.split('\\n')[infos.text.split('\\n').index('JEUNES SÉNIORS VÉTÉRANS HANDIBAD INCLUSIF')+1].split()[2]=='check'\n",
    "\n",
    "            age_group = {'jeunes': jeunes, 'seniors': seniors, 'veterans': veterans}\n",
    "            self.age_group = [key for key, value in age_group.items() if value]\n",
    "            print(','.join(self.age_group))\n",
    "            if self.age_group==[]:\n",
    "                self.age_group = ['jeunes', 'seniors', 'veterans']\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Could not extract age groups for {self.name} ID={self.id}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "\n",
    "        \n",
    "        try:\n",
    "            N = infos.text.split('\\n')[-1].split()[0]=='check'\n",
    "            R = infos.text.split('\\n')[-1].split()[1]=='check'\n",
    "            D = infos.text.split('\\n')[-1].split()[2]=='check'\n",
    "            P = infos.text.split('\\n')[-1].split()[3]=='check'\n",
    "            NC = infos.text.split('\\n')[-1].split()[4]=='check'\n",
    "\n",
    "            categories = {'N': N, 'R': R, 'D': D, 'P': P, 'NC': NC}\n",
    "            self.category = [key for key, value in categories.items() if value]\n",
    "            if self.category == []:\n",
    "                self.category = [ 'N', 'R', 'D','P', 'NC']\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Could not extract category for {self.name} ID={self.id}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "        try:\n",
    "            self.date_registration_opening = dates.text.split('\\n')[1]\n",
    "            self.date_registration_closed = dates.text.split('\\n')[3]\n",
    "        except Exception as e:\n",
    "            logger.error(\"Could not extract registration dates for {self.name} ID={self.id}\")\n",
    "            logger.error(traceback.format_exc())    \n",
    "\n",
    "        self.url_affiche = self.driver.find_element(\"class name\", 'flex.top').find_element(\"tag name\", \"figure\").find_element(\"tag name\", \"a\").get_attribute(\"href\")\n",
    "        \n",
    "        self.driver.quit()\n",
    "    \n",
    "    def is_in_db(self):\n",
    "        if badminton_db.execute(f\"SELECT True FROM tournaments WHERE id={self.id}\").fetchone():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def save_to_db(self):\n",
    "        if not self.is_in_db():\n",
    "            tournament = pd.DataFrame(\n",
    "                {'id':self.id,\n",
    "                'name': self.name,\n",
    "                'url':self.url,\n",
    "                'departement': self.departement, \n",
    "                'date': self.date,\n",
    "                'source': \"badnet\",\n",
    "                'description': self.description,\n",
    "                'date_publication': self.date_publication,\n",
    "                'disciplines' : ','.join(self.disciplines),\n",
    "                'agegroup': ','.join(self.age_group),\n",
    "                'categories': ','.join(self.category)\n",
    "                }, index=[0]\n",
    "                )\n",
    "            tournament.to_sql('tournaments', badminton_db, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '_psutil_linux' could not be imported from 'most likely due to a circular import'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# scraper.py\n",
    "#=============================\n",
    "import os\n",
    "import time\n",
    "import html\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.select import Select\n",
    "\n",
    "\n",
    "from badnet.tournament import Tournament\n",
    "\n",
    "class BadnetScraper:\n",
    "    def __init__(self, url):\n",
    "        self.url=url\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_argument('--window-size=1920x6080')\n",
    "        chromedriver = os.getcwd() + \"/chromedriver\"\n",
    "\n",
    "        self.driver = webdriver.Chrome(options = chrome_options, service=Service(chromedriver))\n",
    "        self.tournaments = []\n",
    "        self.tournaments_df = pd.DataFrame({'id':pd.Series(dtype='str'), \n",
    "            'name': pd.Series(dtype='str'),\n",
    "            'url':pd.Series(dtype='str'),\n",
    "            'departement': pd.Series(dtype='str'), \n",
    "            'date': pd.Series(dtype='str'),\n",
    "            'source': pd.Series(dtype='str'),\n",
    "            'description': pd.Series(dtype='str'),\n",
    "            \"date_publication\": pd.Series(dtype='datetime64[ns]')})\n",
    "\n",
    "    def extract_tournaments(self):\n",
    "        self.driver.get(self.url)\n",
    "        time.sleep(10)\n",
    "\n",
    "        departements = {'75':'62','77':'63','78':'64','91':'65','92':'66','93':'67','94':'68','95':'69'}\n",
    "        for departement, departement_code in departements.items():\n",
    "            print(departement)\n",
    "            print(\"page d'acceuil chargée\")\n",
    "            #ligue_selector = Select(self.driver.find_element(\"id\",\"ligue\"))\n",
    "            #ligue_selector.select_by_value('12')\n",
    "\n",
    "            departement_selector = Select(self.driver.find_element(\"id\",\"departement\"))\n",
    "            departement_selector.select_by_value(departement_code)\n",
    "            time.sleep(1)\n",
    "            \n",
    "\n",
    "            tournaments=self.driver.find_element('id', 'search_results').find_elements('class name', 'events')[0].find_elements('class name', 'row')\n",
    "            try:\n",
    "                pages = self.driver.find_element('class name', 'pager')\n",
    "                next_page = pages.find_element('xpath', '//a[text()=\"›\"]')\n",
    "                pager=\"›\" in pages.text\n",
    "                \n",
    "            except:\n",
    "                pager = False\n",
    "            \n",
    "            for tournament in tournaments:\n",
    "                url = tournament.get_attribute(\"href\")\n",
    "                name = html.unescape(tournament.find_element('class name', 'name').text)\n",
    "                date = tournament.find_element('class name', 'date').text\n",
    "                ville = tournament.find_element('class name', 'location').text\n",
    "                self.tournaments.append(Tournament(name=name, url=url, departement = departement, date=date, ville = ville))\n",
    "                self.tournaments_df = pd.concat([pd.DataFrame({\n",
    "                    'id':url.split(\"=\")[-1],\n",
    "                    'name':name,\n",
    "                    'url':url,\n",
    "                    'departement':departement,\n",
    "                    'date':date,\n",
    "                    'source':'badnet',\n",
    "                    'description': '',\n",
    "                    'date_publication':datetime.now()\n",
    "                }, index=[0]\n",
    "                ),self.tournaments_df.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "            while pager:\n",
    "                next_page.click()    \n",
    "                time.sleep(3)\n",
    "                tournaments=self.driver.find_element('id', 'search_results').find_elements('class name', 'events')[0].find_elements('class name', 'row')\n",
    "                pages = self.driver.find_element('class name', 'pager')\n",
    "                try:\n",
    "                    next_page = pages.find_element('xpath', '//a[text()=\"›\"]')\n",
    "                    pager=\"›\" in pages.text\n",
    "                except:\n",
    "                    pager = False\n",
    "                \n",
    "                for tournament in tournaments:\n",
    "                    url = tournament.get_attribute(\"href\")\n",
    "                    name = html.unescape(tournament.find_element('class name', 'name').text)\n",
    "                    date = tournament.find_element('class name', 'date').text\n",
    "                    ville = tournament.find_element('class name', 'location').text\n",
    "                    self.tournaments.append(Tournament(name=name, url=url, departement = departement, date=date, ville = ville))\n",
    "                    self.tournaments_df = pd.concat([pd.DataFrame({\n",
    "                        'id':url.split(\"=\")[-1],\n",
    "                        'name':name,\n",
    "                        'url':url,\n",
    "                        'departement':departement,\n",
    "                        'date':date,\n",
    "                        'source':'badnet',\n",
    "                        'description': '',\n",
    "                        'date_publication':datetime.now()\n",
    "                    }, index=[0]\n",
    "                    ),self.tournaments_df.loc[:]]).reset_index(drop=True)\n",
    "                print(pages.text, pager)\n",
    "            \n",
    "            time.sleep(1)\n",
    "\n",
    "    def quit(self):\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badnet = BadnetScraper(url = \"https://badnet.fr/accueil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '_psutil_linux' could not be imported from 'most likely due to a circular import'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.select import Select\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--window-size=1920x6080')\n",
    "chromedriver = os.getcwd() + \"/chromedriver\"\n",
    "\n",
    "driver = webdriver.Chrome(options = chrome_options, service=Service(chromedriver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as '_psutil_linux' could not be imported from 'most likely due to a circular import'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
